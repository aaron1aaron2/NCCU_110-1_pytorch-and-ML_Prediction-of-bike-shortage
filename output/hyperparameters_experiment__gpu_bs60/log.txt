K=8, L=1, SE_file='data/train_data/SE/basic/SE.txt', batch_size=60, d=8, decay_epoch=10, device='cuda', learning_rate=0.001, log_file='./output/hyperparameters_experiment__gpu_bs60/log.txt', max_epoch=50, model_file='./output/hyperparameters_experiment__gpu_bs60/model.pkl', num_his=5, num_pred=1, output_folder='./output/hyperparameters_experiment__gpu_bs60', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/hyperparameters_experiment__gpu_bs60
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-10 06:05:42 | epoch: 0001/50, training time: 5.6s, inference time: 0.3s
train loss: 6.1933, val_loss: 5.7836
val loss decrease from inf to 5.7836, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:05:48 | epoch: 0002/50, training time: 5.4s, inference time: 0.3s
train loss: 3.3893, val_loss: 3.9955
val loss decrease from 5.7836 to 3.9955, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:05:53 | epoch: 0003/50, training time: 5.4s, inference time: 0.3s
train loss: 3.2650, val_loss: 3.8988
val loss decrease from 3.9955 to 3.8988, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:05:59 | epoch: 0004/50, training time: 5.4s, inference time: 0.3s
train loss: 3.1870, val_loss: 3.8475
val loss decrease from 3.8988 to 3.8475, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:05 | epoch: 0005/50, training time: 5.4s, inference time: 0.3s
train loss: 3.1268, val_loss: 3.8819
2022-01-10 06:06:10 | epoch: 0006/50, training time: 5.4s, inference time: 0.3s
train loss: 3.0785, val_loss: 3.8059
val loss decrease from 3.8475 to 3.8059, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:16 | epoch: 0007/50, training time: 5.4s, inference time: 0.3s
train loss: 3.0120, val_loss: 3.7602
val loss decrease from 3.8059 to 3.7602, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:22 | epoch: 0008/50, training time: 5.4s, inference time: 0.3s
train loss: 2.9745, val_loss: 3.7483
val loss decrease from 3.7602 to 3.7483, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:27 | epoch: 0009/50, training time: 5.4s, inference time: 0.3s
train loss: 2.9154, val_loss: 3.7084
val loss decrease from 3.7483 to 3.7084, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:33 | epoch: 0010/50, training time: 5.4s, inference time: 0.3s
train loss: 2.8733, val_loss: 3.6899
val loss decrease from 3.7084 to 3.6899, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:39 | epoch: 0011/50, training time: 5.4s, inference time: 0.3s
train loss: 2.8337, val_loss: 3.6926
2022-01-10 06:06:44 | epoch: 0012/50, training time: 5.4s, inference time: 0.3s
train loss: 2.7651, val_loss: 3.6740
val loss decrease from 3.6899 to 3.6740, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:06:50 | epoch: 0013/50, training time: 5.4s, inference time: 0.3s
train loss: 2.7262, val_loss: 3.7244
2022-01-10 06:06:56 | epoch: 0014/50, training time: 5.4s, inference time: 0.3s
train loss: 2.6952, val_loss: 3.6855
2022-01-10 06:07:01 | epoch: 0015/50, training time: 5.4s, inference time: 0.3s
train loss: 2.6700, val_loss: 3.6580
val loss decrease from 3.6740 to 3.6580, saving model to ./output/hyperparameters_experiment__gpu_bs60/model.pkl
2022-01-10 06:07:07 | epoch: 0016/50, training time: 5.4s, inference time: 0.3s
train loss: 2.6299, val_loss: 3.7279
2022-01-10 06:07:13 | epoch: 0017/50, training time: 5.4s, inference time: 0.3s
train loss: 2.5570, val_loss: 3.7718
2022-01-10 06:07:18 | epoch: 0018/50, training time: 5.4s, inference time: 0.3s
train loss: 2.5367, val_loss: 3.7802
2022-01-10 06:07:24 | epoch: 0019/50, training time: 5.4s, inference time: 0.3s
train loss: 2.5141, val_loss: 3.7368
2022-01-10 06:07:30 | epoch: 0020/50, training time: 5.4s, inference time: 0.3s
train loss: 2.4400, val_loss: 3.7283
2022-01-10 06:07:35 | epoch: 0021/50, training time: 5.4s, inference time: 0.2s
train loss: 2.3905, val_loss: 3.7557
2022-01-10 06:07:41 | epoch: 0022/50, training time: 5.4s, inference time: 0.3s
train loss: 2.3636, val_loss: 3.9030
2022-01-10 06:07:47 | epoch: 0023/50, training time: 5.4s, inference time: 0.3s
train loss: 2.3276, val_loss: 3.7521
2022-01-10 06:07:53 | epoch: 0024/50, training time: 5.4s, inference time: 0.2s
train loss: 2.2703, val_loss: 3.7711
2022-01-10 06:07:58 | epoch: 0025/50, training time: 5.4s, inference time: 0.3s
train loss: 2.2368, val_loss: 3.8474
2022-01-10 06:08:04 | epoch: 0026/50, training time: 5.4s, inference time: 0.2s
train loss: 2.2140, val_loss: 3.8566
2022-01-10 06:08:10 | epoch: 0027/50, training time: 5.4s, inference time: 0.3s
train loss: 2.1591, val_loss: 3.8951
2022-01-10 06:08:15 | epoch: 0028/50, training time: 5.4s, inference time: 0.3s
train loss: 2.1246, val_loss: 3.9675
2022-01-10 06:08:21 | epoch: 0029/50, training time: 5.4s, inference time: 0.3s
train loss: 2.0912, val_loss: 4.0489
2022-01-10 06:08:27 | epoch: 0030/50, training time: 5.4s, inference time: 0.3s
train loss: 2.0605, val_loss: 3.9076
2022-01-10 06:08:32 | epoch: 0031/50, training time: 5.5s, inference time: 0.3s
train loss: 2.0069, val_loss: 4.0219
2022-01-10 06:08:38 | epoch: 0032/50, training time: 5.4s, inference time: 0.3s
train loss: 1.9968, val_loss: 3.9813
2022-01-10 06:08:44 | epoch: 0033/50, training time: 5.4s, inference time: 0.3s
train loss: 1.9756, val_loss: 4.0881
2022-01-10 06:08:49 | epoch: 0034/50, training time: 5.4s, inference time: 0.3s
train loss: 1.9331, val_loss: 4.0354
2022-01-10 06:08:55 | epoch: 0035/50, training time: 5.4s, inference time: 0.3s
train loss: 1.8935, val_loss: 4.1047
2022-01-10 06:09:01 | epoch: 0036/50, training time: 5.4s, inference time: 0.3s
train loss: 1.8334, val_loss: 4.1496
2022-01-10 06:09:06 | epoch: 0037/50, training time: 5.4s, inference time: 0.3s
train loss: 1.8186, val_loss: 4.1884
2022-01-10 06:09:12 | epoch: 0038/50, training time: 5.4s, inference time: 0.3s
train loss: 1.7951, val_loss: 4.2689
2022-01-10 06:09:18 | epoch: 0039/50, training time: 5.4s, inference time: 0.3s
train loss: 1.7960, val_loss: 4.1754
2022-01-10 06:09:23 | epoch: 0040/50, training time: 5.4s, inference time: 0.3s
train loss: 1.7153, val_loss: 4.2413
2022-01-10 06:09:29 | epoch: 0041/50, training time: 5.4s, inference time: 0.3s
train loss: 1.7147, val_loss: 4.4071
2022-01-10 06:09:35 | epoch: 0042/50, training time: 5.4s, inference time: 0.3s
train loss: 1.6463, val_loss: 4.2988
2022-01-10 06:09:40 | epoch: 0043/50, training time: 5.4s, inference time: 0.3s
train loss: 1.6458, val_loss: 4.4083
2022-01-10 06:09:46 | epoch: 0044/50, training time: 5.4s, inference time: 0.3s
train loss: 1.6616, val_loss: 4.3518
2022-01-10 06:09:52 | epoch: 0045/50, training time: 5.4s, inference time: 0.3s
train loss: 1.5984, val_loss: 4.5610
2022-01-10 06:09:57 | epoch: 0046/50, training time: 5.4s, inference time: 0.2s
train loss: 1.5498, val_loss: 4.4574
2022-01-10 06:10:03 | epoch: 0047/50, training time: 5.5s, inference time: 0.3s
train loss: 1.5684, val_loss: 4.4436
2022-01-10 06:10:09 | epoch: 0048/50, training time: 5.4s, inference time: 0.3s
train loss: 1.5282, val_loss: 4.6608
2022-01-10 06:10:14 | epoch: 0049/50, training time: 5.4s, inference time: 0.3s
train loss: 1.5554, val_loss: 4.6338
2022-01-10 06:10:20 | epoch: 0050/50, training time: 5.4s, inference time: 0.3s
train loss: 1.5121, val_loss: 4.6150
Training and validation are completed, and model has been stored as ./output/hyperparameters_experiment__gpu_bs60/model.pkl
**** testing model ****
loading model from ./output/hyperparameters_experiment__gpu_bs60/model.pkl
model restored!
evaluating...
testing time: 0.5s
                MAE		RMSE		MAPE
train            0.74		1.15		11.23%
val              1.37		2.18		20.16%
test             1.26		2.10		18.63%
performance in each prediction step
step: 01         1.26		2.10		18.63%
average:         1.26		2.10		18.63%
total time: 4.8min
