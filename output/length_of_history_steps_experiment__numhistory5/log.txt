K=8, L=1, SE_file='data/train_data/SE/basic/SE.txt', batch_size=24, d=8, decay_epoch=10, device='cuda', learning_rate=0.01, log_file='./output/length_of_history_steps_experiment__numhistory5/log.txt', max_epoch=50, model_file='./output/length_of_history_steps_experiment__numhistory5/model.pkl', num_his=5, num_pred=1, output_folder='./output/length_of_history_steps_experiment__numhistory5', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/length_of_history_steps_experiment__numhistory5
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-12 15:59:10 | epoch: 0001/50, training time: 9.7s, inference time: 0.4s
train loss: 4.2551, val_loss: 4.2735
val loss decrease from inf to 4.2735, saving model to ./output/length_of_history_steps_experiment__numhistory5/model.pkl
2022-01-12 15:59:20 | epoch: 0002/50, training time: 9.7s, inference time: 0.4s
train loss: 3.1596, val_loss: 3.6662
val loss decrease from 4.2735 to 3.6662, saving model to ./output/length_of_history_steps_experiment__numhistory5/model.pkl
2022-01-12 15:59:30 | epoch: 0003/50, training time: 9.6s, inference time: 0.4s
train loss: 3.0590, val_loss: 3.5683
val loss decrease from 3.6662 to 3.5683, saving model to ./output/length_of_history_steps_experiment__numhistory5/model.pkl
2022-01-12 15:59:40 | epoch: 0004/50, training time: 9.7s, inference time: 0.4s
train loss: 2.9547, val_loss: 3.4195
val loss decrease from 3.5683 to 3.4195, saving model to ./output/length_of_history_steps_experiment__numhistory5/model.pkl
2022-01-12 15:59:50 | epoch: 0005/50, training time: 9.8s, inference time: 0.4s
train loss: 2.9404, val_loss: 3.6866
2022-01-12 16:00:00 | epoch: 0006/50, training time: 9.9s, inference time: 0.4s
train loss: 2.9005, val_loss: 3.5656
2022-01-12 16:00:11 | epoch: 0007/50, training time: 9.7s, inference time: 0.4s
train loss: 2.8300, val_loss: 3.4053
val loss decrease from 3.4195 to 3.4053, saving model to ./output/length_of_history_steps_experiment__numhistory5/model.pkl
2022-01-12 16:00:21 | epoch: 0008/50, training time: 9.7s, inference time: 0.4s
train loss: 2.7918, val_loss: 3.6179
2022-01-12 16:00:31 | epoch: 0009/50, training time: 9.8s, inference time: 0.4s
train loss: 2.7740, val_loss: 3.4633
2022-01-12 16:00:41 | epoch: 0010/50, training time: 9.7s, inference time: 0.4s
train loss: 2.7480, val_loss: 3.7503
2022-01-12 16:00:51 | epoch: 0011/50, training time: 9.7s, inference time: 0.4s
train loss: 2.6857, val_loss: 3.5321
2022-01-12 16:01:01 | epoch: 0012/50, training time: 9.7s, inference time: 0.4s
train loss: 2.6638, val_loss: 3.5484
2022-01-12 16:01:11 | epoch: 0013/50, training time: 9.7s, inference time: 0.4s
train loss: 2.6231, val_loss: 3.5284
2022-01-12 16:01:22 | epoch: 0014/50, training time: 9.7s, inference time: 0.4s
train loss: 2.5838, val_loss: 3.7119
2022-01-12 16:01:32 | epoch: 0015/50, training time: 9.6s, inference time: 0.4s
train loss: 2.5507, val_loss: 3.7233
2022-01-12 16:01:41 | epoch: 0016/50, training time: 9.5s, inference time: 0.4s
train loss: 2.4939, val_loss: 3.8443
2022-01-12 16:01:51 | epoch: 0017/50, training time: 9.6s, inference time: 0.4s
train loss: 2.4930, val_loss: 3.7889
2022-01-12 16:02:01 | epoch: 0018/50, training time: 9.5s, inference time: 0.4s
train loss: 2.4483, val_loss: 3.9096
2022-01-12 16:02:11 | epoch: 0019/50, training time: 9.4s, inference time: 0.4s
train loss: 2.3881, val_loss: 3.8022
2022-01-12 16:02:21 | epoch: 0020/50, training time: 9.5s, inference time: 0.4s
train loss: 2.3808, val_loss: 3.7848
2022-01-12 16:02:31 | epoch: 0021/50, training time: 9.6s, inference time: 0.4s
train loss: 2.3135, val_loss: 3.5340
2022-01-12 16:02:41 | epoch: 0022/50, training time: 9.7s, inference time: 0.4s
train loss: 2.2546, val_loss: 3.6355
2022-01-12 16:02:51 | epoch: 0023/50, training time: 9.5s, inference time: 0.4s
train loss: 2.2212, val_loss: 3.7234
2022-01-12 16:03:01 | epoch: 0024/50, training time: 9.6s, inference time: 0.4s
train loss: 2.1824, val_loss: 3.7950
2022-01-12 16:03:12 | epoch: 0025/50, training time: 9.7s, inference time: 0.4s
train loss: 2.1423, val_loss: 3.8139
2022-01-12 16:03:21 | epoch: 0026/50, training time: 9.5s, inference time: 0.4s
train loss: 2.1605, val_loss: 3.9416
2022-01-12 16:03:31 | epoch: 0027/50, training time: 9.5s, inference time: 0.4s
train loss: 2.0961, val_loss: 3.7623
2022-01-12 16:03:42 | epoch: 0028/50, training time: 9.7s, inference time: 0.4s
train loss: 2.0164, val_loss: 3.9030
2022-01-12 16:03:52 | epoch: 0029/50, training time: 9.8s, inference time: 0.4s
train loss: 1.9936, val_loss: 4.2134
2022-01-12 16:04:02 | epoch: 0030/50, training time: 9.6s, inference time: 0.4s
train loss: 1.9881, val_loss: 3.7467
2022-01-12 16:04:12 | epoch: 0031/50, training time: 9.5s, inference time: 0.4s
train loss: 1.9198, val_loss: 3.9818
2022-01-12 16:04:22 | epoch: 0032/50, training time: 9.6s, inference time: 0.4s
train loss: 1.8498, val_loss: 3.9229
2022-01-12 16:04:32 | epoch: 0033/50, training time: 9.5s, inference time: 0.4s
train loss: 1.8729, val_loss: 4.0665
2022-01-12 16:04:42 | epoch: 0034/50, training time: 9.6s, inference time: 0.4s
train loss: 1.8103, val_loss: 3.9129
2022-01-12 16:04:52 | epoch: 0035/50, training time: 9.6s, inference time: 0.4s
train loss: 1.7783, val_loss: 4.0644
2022-01-12 16:05:02 | epoch: 0036/50, training time: 9.5s, inference time: 0.4s
train loss: 1.7771, val_loss: 3.8265
2022-01-12 16:05:12 | epoch: 0037/50, training time: 9.7s, inference time: 0.4s
train loss: 1.7518, val_loss: 4.5785
2022-01-12 16:05:22 | epoch: 0038/50, training time: 9.7s, inference time: 0.4s
train loss: 1.7235, val_loss: 4.6252
2022-01-12 16:05:32 | epoch: 0039/50, training time: 9.6s, inference time: 0.4s
train loss: 1.6845, val_loss: 3.8748
2022-01-12 16:05:42 | epoch: 0040/50, training time: 9.5s, inference time: 0.4s
train loss: 1.6994, val_loss: 4.1631
2022-01-12 16:05:52 | epoch: 0041/50, training time: 9.5s, inference time: 0.4s
train loss: 1.6240, val_loss: 3.8675
2022-01-12 16:06:02 | epoch: 0042/50, training time: 9.6s, inference time: 0.4s
train loss: 1.6242, val_loss: 4.2000
2022-01-12 16:06:12 | epoch: 0043/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5787, val_loss: 4.0756
2022-01-12 16:06:22 | epoch: 0044/50, training time: 9.6s, inference time: 0.4s
train loss: 1.5691, val_loss: 3.8783
2022-01-12 16:06:32 | epoch: 0045/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5887, val_loss: 4.0492
2022-01-12 16:06:42 | epoch: 0046/50, training time: 9.7s, inference time: 0.4s
train loss: 1.5676, val_loss: 4.1068
2022-01-12 16:06:52 | epoch: 0047/50, training time: 9.6s, inference time: 0.4s
train loss: 1.5371, val_loss: 3.8992
2022-01-12 16:07:02 | epoch: 0048/50, training time: 9.7s, inference time: 0.4s
train loss: 1.5170, val_loss: 4.2382
2022-01-12 16:07:12 | epoch: 0049/50, training time: 9.6s, inference time: 0.4s
train loss: 1.4724, val_loss: 4.0862
2022-01-12 16:07:22 | epoch: 0050/50, training time: 9.5s, inference time: 0.4s
train loss: 1.4866, val_loss: 4.2927
Training and validation are completed, and model has been stored as ./output/length_of_history_steps_experiment__numhistory5/model.pkl
**** testing model ****
loading model from ./output/length_of_history_steps_experiment__numhistory5/model.pkl
model restored!
evaluating...
testing time: 0.8s
                MAE		RMSE		MAPE
train            0.69		1.12		10.02%
val              1.25		2.11		18.14%
test             1.09		1.98		16.19%
performance in each prediction step
step: 01         1.09		1.98		16.19%
average:         1.09		1.98		16.19%
total time: 8.4min
