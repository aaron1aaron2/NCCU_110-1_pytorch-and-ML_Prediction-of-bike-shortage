K=8, L=1, SE_file='./data/train_data/SE/test_adj/adj0.20827/SE.txt', batch_size=24, d=8, decay_epoch=10, device='cuda', learning_rate=0.01, log_file='./output/adj_threshold_experiment__th(0.20827)_mean/log.txt', max_epoch=50, model_file='./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl', num_his=5, num_pred=1, output_folder='./output/adj_threshold_experiment__th(0.20827)_mean', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/adj_threshold_experiment__th(0.20827)_mean
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-11 16:22:32 | epoch: 0001/50, training time: 9.4s, inference time: 0.4s
train loss: 4.2427, val_loss: 3.6736
val loss decrease from inf to 3.6736, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:22:42 | epoch: 0002/50, training time: 9.3s, inference time: 0.4s
train loss: 3.1727, val_loss: 3.6216
val loss decrease from 3.6736 to 3.6216, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:22:52 | epoch: 0003/50, training time: 9.4s, inference time: 0.4s
train loss: 3.0680, val_loss: 3.5443
val loss decrease from 3.6216 to 3.5443, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:23:02 | epoch: 0004/50, training time: 9.4s, inference time: 0.4s
train loss: 3.0032, val_loss: 3.4786
val loss decrease from 3.5443 to 3.4786, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:23:11 | epoch: 0005/50, training time: 9.5s, inference time: 0.4s
train loss: 2.8840, val_loss: 3.4178
val loss decrease from 3.4786 to 3.4178, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:23:21 | epoch: 0006/50, training time: 9.5s, inference time: 0.4s
train loss: 2.9171, val_loss: 3.4153
val loss decrease from 3.4178 to 3.4153, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:23:31 | epoch: 0007/50, training time: 9.5s, inference time: 0.4s
train loss: 2.8552, val_loss: 3.5395
2022-01-11 16:23:41 | epoch: 0008/50, training time: 9.5s, inference time: 0.4s
train loss: 2.8290, val_loss: 3.4540
2022-01-11 16:23:51 | epoch: 0009/50, training time: 9.5s, inference time: 0.4s
train loss: 2.8010, val_loss: 3.3963
val loss decrease from 3.4153 to 3.3963, saving model to ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
2022-01-11 16:24:01 | epoch: 0010/50, training time: 9.4s, inference time: 0.4s
train loss: 2.7764, val_loss: 3.4841
2022-01-11 16:24:11 | epoch: 0011/50, training time: 9.4s, inference time: 0.4s
train loss: 2.7278, val_loss: 3.4708
2022-01-11 16:24:20 | epoch: 0012/50, training time: 9.5s, inference time: 0.4s
train loss: 2.6542, val_loss: 3.5652
2022-01-11 16:24:30 | epoch: 0013/50, training time: 9.4s, inference time: 0.4s
train loss: 2.6338, val_loss: 3.4651
2022-01-11 16:24:40 | epoch: 0014/50, training time: 9.6s, inference time: 0.4s
train loss: 2.6366, val_loss: 3.4675
2022-01-11 16:24:50 | epoch: 0015/50, training time: 9.5s, inference time: 0.4s
train loss: 2.5701, val_loss: 3.6233
2022-01-11 16:25:00 | epoch: 0016/50, training time: 9.6s, inference time: 0.4s
train loss: 2.5418, val_loss: 3.5307
2022-01-11 16:25:10 | epoch: 0017/50, training time: 9.4s, inference time: 0.4s
train loss: 2.4903, val_loss: 3.5684
2022-01-11 16:25:20 | epoch: 0018/50, training time: 9.6s, inference time: 0.4s
train loss: 2.5215, val_loss: 3.5277
2022-01-11 16:25:30 | epoch: 0019/50, training time: 9.4s, inference time: 0.4s
train loss: 2.4378, val_loss: 3.6019
2022-01-11 16:25:40 | epoch: 0020/50, training time: 9.5s, inference time: 0.4s
train loss: 2.3973, val_loss: 3.5116
2022-01-11 16:25:50 | epoch: 0021/50, training time: 9.5s, inference time: 0.4s
train loss: 2.3322, val_loss: 3.6209
2022-01-11 16:26:00 | epoch: 0022/50, training time: 9.4s, inference time: 0.4s
train loss: 2.2852, val_loss: 3.6399
2022-01-11 16:26:09 | epoch: 0023/50, training time: 9.4s, inference time: 0.4s
train loss: 2.2823, val_loss: 3.7744
2022-01-11 16:26:19 | epoch: 0024/50, training time: 9.5s, inference time: 0.4s
train loss: 2.2624, val_loss: 3.7664
2022-01-11 16:26:29 | epoch: 0025/50, training time: 9.3s, inference time: 0.4s
train loss: 2.1903, val_loss: 3.7242
2022-01-11 16:26:39 | epoch: 0026/50, training time: 9.6s, inference time: 0.4s
train loss: 2.1547, val_loss: 3.7581
2022-01-11 16:26:49 | epoch: 0027/50, training time: 9.4s, inference time: 0.4s
train loss: 2.0723, val_loss: 3.8598
2022-01-11 16:26:59 | epoch: 0028/50, training time: 9.4s, inference time: 0.4s
train loss: 2.0829, val_loss: 3.7978
2022-01-11 16:27:08 | epoch: 0029/50, training time: 9.5s, inference time: 0.4s
train loss: 2.0678, val_loss: 3.9230
2022-01-11 16:27:18 | epoch: 0030/50, training time: 9.4s, inference time: 0.4s
train loss: 2.0423, val_loss: 3.7608
2022-01-11 16:27:28 | epoch: 0031/50, training time: 9.5s, inference time: 0.4s
train loss: 1.9803, val_loss: 3.6430
2022-01-11 16:27:38 | epoch: 0032/50, training time: 9.6s, inference time: 0.4s
train loss: 1.8911, val_loss: 3.7937
2022-01-11 16:27:48 | epoch: 0033/50, training time: 9.5s, inference time: 0.4s
train loss: 1.8865, val_loss: 3.9167
2022-01-11 16:27:58 | epoch: 0034/50, training time: 9.5s, inference time: 0.4s
train loss: 1.8343, val_loss: 3.8227
2022-01-11 16:28:08 | epoch: 0035/50, training time: 9.4s, inference time: 0.4s
train loss: 1.8267, val_loss: 3.9093
2022-01-11 16:28:18 | epoch: 0036/50, training time: 9.6s, inference time: 0.4s
train loss: 1.8447, val_loss: 3.9615
2022-01-11 16:28:28 | epoch: 0037/50, training time: 9.6s, inference time: 0.4s
train loss: 1.8223, val_loss: 3.9094
2022-01-11 16:28:38 | epoch: 0038/50, training time: 9.4s, inference time: 0.4s
train loss: 1.7649, val_loss: 3.9922
2022-01-11 16:28:47 | epoch: 0039/50, training time: 9.5s, inference time: 0.4s
train loss: 1.7405, val_loss: 3.9825
2022-01-11 16:28:57 | epoch: 0040/50, training time: 9.5s, inference time: 0.4s
train loss: 1.7388, val_loss: 4.0040
2022-01-11 16:29:07 | epoch: 0041/50, training time: 9.6s, inference time: 0.4s
train loss: 1.6400, val_loss: 3.9377
2022-01-11 16:29:17 | epoch: 0042/50, training time: 9.5s, inference time: 0.4s
train loss: 1.6222, val_loss: 4.2581
2022-01-11 16:29:27 | epoch: 0043/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5986, val_loss: 4.0138
2022-01-11 16:29:37 | epoch: 0044/50, training time: 9.5s, inference time: 0.4s
train loss: 1.6052, val_loss: 4.0170
2022-01-11 16:29:47 | epoch: 0045/50, training time: 9.5s, inference time: 0.4s
train loss: 1.6003, val_loss: 3.9511
2022-01-11 16:29:57 | epoch: 0046/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5429, val_loss: 4.0394
2022-01-11 16:30:07 | epoch: 0047/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5473, val_loss: 4.2169
2022-01-11 16:30:17 | epoch: 0048/50, training time: 9.4s, inference time: 0.4s
train loss: 1.5446, val_loss: 4.3125
2022-01-11 16:30:26 | epoch: 0049/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5734, val_loss: 4.3775
2022-01-11 16:30:36 | epoch: 0050/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5732, val_loss: 4.0333
Training and validation are completed, and model has been stored as ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
**** testing model ****
loading model from ./output/adj_threshold_experiment__th(0.20827)_mean/model.pkl
model restored!
evaluating...
testing time: 0.8s
                MAE		RMSE		MAPE
train            0.71		1.15		10.71%
val              1.24		2.04		18.63%
test             1.09		1.92		16.94%
performance in each prediction step
step: 01         1.09		1.92		16.94%
average:         1.09		1.92		16.94%
total time: 8.3min
