K=8, L=1, SE_file='./data/train_data/SE/basic/SE.txt', batch_size=24, d=8, decay_epoch=10, device='cuda', learning_rate=0.01, log_file='./output/basic/log.txt', max_epoch=100, model_file='./output/basic/model.pkl', num_his=5, num_pred=1, output_folder='./output/basic', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/basic
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-13 03:19:32 | epoch: 0001/100, training time: 7.2s, inference time: 0.4s
train loss: 4.3899, val_loss: 3.7539
val loss decrease from inf to 3.7539, saving model to ./output/basic/model.pkl
2022-01-13 03:19:39 | epoch: 0002/100, training time: 6.7s, inference time: 0.4s
train loss: 3.1908, val_loss: 3.6017
val loss decrease from 3.7539 to 3.6017, saving model to ./output/basic/model.pkl
2022-01-13 03:19:46 | epoch: 0003/100, training time: 6.7s, inference time: 0.3s
train loss: 3.0566, val_loss: 3.5247
val loss decrease from 3.6017 to 3.5247, saving model to ./output/basic/model.pkl
2022-01-13 03:19:53 | epoch: 0004/100, training time: 6.7s, inference time: 0.3s
train loss: 2.9786, val_loss: 3.6185
2022-01-13 03:20:00 | epoch: 0005/100, training time: 6.7s, inference time: 0.4s
train loss: 2.9478, val_loss: 3.5075
val loss decrease from 3.5247 to 3.5075, saving model to ./output/basic/model.pkl
2022-01-13 03:20:07 | epoch: 0006/100, training time: 6.8s, inference time: 0.3s
train loss: 2.9119, val_loss: 3.6667
2022-01-13 03:20:14 | epoch: 0007/100, training time: 6.7s, inference time: 0.3s
train loss: 2.8663, val_loss: 3.5009
val loss decrease from 3.5075 to 3.5009, saving model to ./output/basic/model.pkl
2022-01-13 03:20:21 | epoch: 0008/100, training time: 6.6s, inference time: 0.3s
train loss: 2.8070, val_loss: 3.4665
val loss decrease from 3.5009 to 3.4665, saving model to ./output/basic/model.pkl
2022-01-13 03:20:28 | epoch: 0009/100, training time: 6.6s, inference time: 0.3s
train loss: 2.7787, val_loss: 3.4146
val loss decrease from 3.4665 to 3.4146, saving model to ./output/basic/model.pkl
2022-01-13 03:20:35 | epoch: 0010/100, training time: 6.6s, inference time: 0.4s
train loss: 2.7363, val_loss: 3.3935
val loss decrease from 3.4146 to 3.3935, saving model to ./output/basic/model.pkl
2022-01-13 03:20:42 | epoch: 0011/100, training time: 6.6s, inference time: 0.4s
train loss: 2.6642, val_loss: 3.4605
2022-01-13 03:20:49 | epoch: 0012/100, training time: 6.5s, inference time: 0.3s
train loss: 2.6570, val_loss: 3.5774
2022-01-13 03:20:56 | epoch: 0013/100, training time: 6.5s, inference time: 0.4s
train loss: 2.6389, val_loss: 3.4978
2022-01-13 03:21:03 | epoch: 0014/100, training time: 6.6s, inference time: 0.4s
train loss: 2.5651, val_loss: 3.6022
2022-01-13 03:21:09 | epoch: 0015/100, training time: 6.5s, inference time: 0.4s
train loss: 2.5565, val_loss: 3.9013
2022-01-13 03:21:16 | epoch: 0016/100, training time: 6.5s, inference time: 0.3s
train loss: 2.5432, val_loss: 3.5912
2022-01-13 03:21:23 | epoch: 0017/100, training time: 6.7s, inference time: 0.4s
train loss: 2.4704, val_loss: 3.8309
2022-01-13 03:21:30 | epoch: 0018/100, training time: 6.7s, inference time: 0.3s
train loss: 2.4203, val_loss: 3.5994
2022-01-13 03:21:37 | epoch: 0019/100, training time: 6.6s, inference time: 0.3s
train loss: 2.3965, val_loss: 3.9074
2022-01-13 03:21:44 | epoch: 0020/100, training time: 6.6s, inference time: 0.4s
train loss: 2.3778, val_loss: 3.5116
2022-01-13 03:21:51 | epoch: 0021/100, training time: 6.5s, inference time: 0.4s
train loss: 2.3130, val_loss: 3.5779
2022-01-13 03:21:58 | epoch: 0022/100, training time: 6.7s, inference time: 0.3s
train loss: 2.2747, val_loss: 3.6855
2022-01-13 03:22:05 | epoch: 0023/100, training time: 6.6s, inference time: 0.3s
train loss: 2.2423, val_loss: 3.7247
2022-01-13 03:22:12 | epoch: 0024/100, training time: 6.6s, inference time: 0.3s
train loss: 2.1784, val_loss: 3.5699
2022-01-13 03:22:19 | epoch: 0025/100, training time: 6.7s, inference time: 0.4s
train loss: 2.1828, val_loss: 3.7334
2022-01-13 03:22:26 | epoch: 0026/100, training time: 6.6s, inference time: 0.4s
train loss: 2.1308, val_loss: 3.8267
2022-01-13 03:22:33 | epoch: 0027/100, training time: 6.5s, inference time: 0.4s
train loss: 2.0809, val_loss: 3.5990
2022-01-13 03:22:40 | epoch: 0028/100, training time: 6.5s, inference time: 0.3s
train loss: 2.0642, val_loss: 3.8847
2022-01-13 03:22:47 | epoch: 0029/100, training time: 6.5s, inference time: 0.3s
train loss: 2.0431, val_loss: 3.7532
2022-01-13 03:22:54 | epoch: 0030/100, training time: 6.6s, inference time: 0.4s
train loss: 2.0030, val_loss: 3.9819
2022-01-13 03:23:00 | epoch: 0031/100, training time: 6.6s, inference time: 0.4s
train loss: 1.9189, val_loss: 3.8796
2022-01-13 03:23:07 | epoch: 0032/100, training time: 6.5s, inference time: 0.3s
train loss: 1.8870, val_loss: 4.0231
2022-01-13 03:23:14 | epoch: 0033/100, training time: 6.5s, inference time: 0.3s
train loss: 1.8822, val_loss: 3.9468
2022-01-13 03:23:21 | epoch: 0034/100, training time: 6.4s, inference time: 0.3s
train loss: 1.8435, val_loss: 3.9269
2022-01-13 03:23:28 | epoch: 0035/100, training time: 6.5s, inference time: 0.4s
train loss: 1.8303, val_loss: 4.0946
2022-01-13 03:23:35 | epoch: 0036/100, training time: 6.6s, inference time: 0.4s
train loss: 1.8088, val_loss: 3.9171
2022-01-13 03:23:42 | epoch: 0037/100, training time: 6.5s, inference time: 0.3s
train loss: 1.7848, val_loss: 3.8943
2022-01-13 03:23:49 | epoch: 0038/100, training time: 6.7s, inference time: 0.3s
train loss: 1.7584, val_loss: 4.0537
2022-01-13 03:23:55 | epoch: 0039/100, training time: 6.5s, inference time: 0.4s
train loss: 1.7389, val_loss: 4.1185
2022-01-13 03:24:02 | epoch: 0040/100, training time: 6.5s, inference time: 0.4s
train loss: 1.7410, val_loss: 4.1610
2022-01-13 03:24:09 | epoch: 0041/100, training time: 6.6s, inference time: 0.3s
train loss: 1.6492, val_loss: 4.1866
2022-01-13 03:24:16 | epoch: 0042/100, training time: 6.6s, inference time: 0.4s
train loss: 1.6139, val_loss: 4.3681
2022-01-13 03:24:23 | epoch: 0043/100, training time: 6.6s, inference time: 0.4s
train loss: 1.6355, val_loss: 4.1966
2022-01-13 03:24:30 | epoch: 0044/100, training time: 6.7s, inference time: 0.4s
train loss: 1.5845, val_loss: 4.1007
2022-01-13 03:24:37 | epoch: 0045/100, training time: 6.6s, inference time: 0.3s
train loss: 1.5564, val_loss: 4.2432
2022-01-13 03:24:44 | epoch: 0046/100, training time: 6.6s, inference time: 0.3s
train loss: 1.6131, val_loss: 4.2368
2022-01-13 03:24:51 | epoch: 0047/100, training time: 6.5s, inference time: 0.3s
train loss: 1.5954, val_loss: 4.1876
2022-01-13 03:24:58 | epoch: 0048/100, training time: 6.5s, inference time: 0.3s
train loss: 1.5260, val_loss: 4.3196
2022-01-13 03:25:05 | epoch: 0049/100, training time: 6.7s, inference time: 0.4s
train loss: 1.5804, val_loss: 4.2015
2022-01-13 03:25:12 | epoch: 0050/100, training time: 6.6s, inference time: 0.3s
train loss: 1.5344, val_loss: 4.1523
2022-01-13 03:25:19 | epoch: 0051/100, training time: 6.6s, inference time: 0.4s
train loss: 1.4952, val_loss: 4.3118
2022-01-13 03:25:26 | epoch: 0052/100, training time: 6.6s, inference time: 0.3s
train loss: 1.4479, val_loss: 4.4275
2022-01-13 03:25:33 | epoch: 0053/100, training time: 6.6s, inference time: 0.4s
train loss: 1.4384, val_loss: 4.2672
2022-01-13 03:25:40 | epoch: 0054/100, training time: 6.7s, inference time: 0.3s
train loss: 1.4201, val_loss: 4.2372
2022-01-13 03:25:47 | epoch: 0055/100, training time: 6.5s, inference time: 0.4s
train loss: 1.3911, val_loss: 4.4591
2022-01-13 03:25:53 | epoch: 0056/100, training time: 6.5s, inference time: 0.4s
train loss: 1.4076, val_loss: 4.2202
2022-01-13 03:26:00 | epoch: 0057/100, training time: 6.5s, inference time: 0.4s
train loss: 1.4059, val_loss: 4.7018
2022-01-13 03:26:07 | epoch: 0058/100, training time: 6.6s, inference time: 0.3s
train loss: 1.4140, val_loss: 4.4916
2022-01-13 03:26:14 | epoch: 0059/100, training time: 6.7s, inference time: 0.3s
train loss: 1.3930, val_loss: 4.4961
2022-01-13 03:26:21 | epoch: 0060/100, training time: 6.6s, inference time: 0.3s
train loss: 1.3578, val_loss: 5.1350
2022-01-13 03:26:28 | epoch: 0061/100, training time: 6.5s, inference time: 0.3s
train loss: 1.3145, val_loss: 4.8880
2022-01-13 03:26:35 | epoch: 0062/100, training time: 6.5s, inference time: 0.3s
train loss: 1.2952, val_loss: 4.5398
2022-01-13 03:26:42 | epoch: 0063/100, training time: 6.5s, inference time: 0.4s
train loss: 1.2407, val_loss: 4.7124
2022-01-13 03:26:49 | epoch: 0064/100, training time: 6.7s, inference time: 0.4s
train loss: 1.2663, val_loss: 4.4545
2022-01-13 03:26:56 | epoch: 0065/100, training time: 6.6s, inference time: 0.3s
train loss: 1.2355, val_loss: 4.4750
2022-01-13 03:27:03 | epoch: 0066/100, training time: 6.6s, inference time: 0.3s
train loss: 1.2661, val_loss: 4.7336
2022-01-13 03:27:10 | epoch: 0067/100, training time: 6.6s, inference time: 0.4s
train loss: 1.2508, val_loss: 4.6458
2022-01-13 03:27:17 | epoch: 0068/100, training time: 6.7s, inference time: 0.4s
train loss: 1.1941, val_loss: 4.8153
2022-01-13 03:27:24 | epoch: 0069/100, training time: 6.5s, inference time: 0.3s
train loss: 1.2161, val_loss: 4.6895
2022-01-13 03:27:30 | epoch: 0070/100, training time: 6.4s, inference time: 0.3s
train loss: 1.1989, val_loss: 4.7121
2022-01-13 03:27:37 | epoch: 0071/100, training time: 6.5s, inference time: 0.3s
train loss: 1.1460, val_loss: 4.9352
2022-01-13 03:27:44 | epoch: 0072/100, training time: 6.5s, inference time: 0.4s
train loss: 1.1696, val_loss: 4.8068
2022-01-13 03:27:51 | epoch: 0073/100, training time: 6.6s, inference time: 0.3s
train loss: 1.1810, val_loss: 4.8807
2022-01-13 03:27:58 | epoch: 0074/100, training time: 6.6s, inference time: 0.4s
train loss: 1.1627, val_loss: 4.6428
2022-01-13 03:28:05 | epoch: 0075/100, training time: 6.6s, inference time: 0.3s
train loss: 1.1179, val_loss: 4.5334
2022-01-13 03:28:12 | epoch: 0076/100, training time: 6.6s, inference time: 0.3s
train loss: 1.1338, val_loss: 4.7881
2022-01-13 03:28:19 | epoch: 0077/100, training time: 6.4s, inference time: 0.4s
train loss: 1.1259, val_loss: 4.7903
2022-01-13 03:28:25 | epoch: 0078/100, training time: 6.5s, inference time: 0.3s
train loss: 1.0874, val_loss: 4.6808
2022-01-13 03:28:32 | epoch: 0079/100, training time: 6.6s, inference time: 0.4s
train loss: 1.0833, val_loss: 4.5872
2022-01-13 03:28:39 | epoch: 0080/100, training time: 6.6s, inference time: 0.3s
train loss: 1.1236, val_loss: 4.9532
2022-01-13 03:28:46 | epoch: 0081/100, training time: 6.6s, inference time: 0.3s
train loss: 1.0554, val_loss: 4.9798
2022-01-13 03:28:53 | epoch: 0082/100, training time: 6.4s, inference time: 0.3s
train loss: 1.0421, val_loss: 5.2217
2022-01-13 03:29:00 | epoch: 0083/100, training time: 6.5s, inference time: 0.3s
train loss: 1.0473, val_loss: 5.0152
2022-01-13 03:29:07 | epoch: 0084/100, training time: 6.5s, inference time: 0.3s
train loss: 1.0258, val_loss: 5.2831
2022-01-13 03:29:14 | epoch: 0085/100, training time: 6.6s, inference time: 0.4s
train loss: 1.0353, val_loss: 4.9568
2022-01-13 03:29:21 | epoch: 0086/100, training time: 6.7s, inference time: 0.4s
train loss: 1.0213, val_loss: 5.0856
2022-01-13 03:29:28 | epoch: 0087/100, training time: 6.6s, inference time: 0.4s
train loss: 0.9702, val_loss: 4.8742
2022-01-13 03:29:35 | epoch: 0088/100, training time: 6.6s, inference time: 0.3s
train loss: 0.9904, val_loss: 4.8861
2022-01-13 03:29:42 | epoch: 0089/100, training time: 6.6s, inference time: 0.4s
train loss: 0.9919, val_loss: 4.6760
2022-01-13 03:29:48 | epoch: 0090/100, training time: 6.5s, inference time: 0.4s
train loss: 0.9745, val_loss: 5.1143
2022-01-13 03:29:55 | epoch: 0091/100, training time: 6.5s, inference time: 0.3s
train loss: 0.9622, val_loss: 5.1039
2022-01-13 03:30:02 | epoch: 0092/100, training time: 6.6s, inference time: 0.4s
train loss: 0.9644, val_loss: 5.2959
2022-01-13 03:30:09 | epoch: 0093/100, training time: 6.6s, inference time: 0.3s
train loss: 0.9517, val_loss: 4.9873
2022-01-13 03:30:16 | epoch: 0094/100, training time: 6.5s, inference time: 0.4s
train loss: 0.9616, val_loss: 4.9541
2022-01-13 03:30:23 | epoch: 0095/100, training time: 6.6s, inference time: 0.4s
train loss: 0.9456, val_loss: 5.1056
2022-01-13 03:30:30 | epoch: 0096/100, training time: 6.5s, inference time: 0.4s
train loss: 0.9178, val_loss: 5.1668
2022-01-13 03:30:37 | epoch: 0097/100, training time: 6.6s, inference time: 0.3s
train loss: 0.9269, val_loss: 4.9988
2022-01-13 03:30:43 | epoch: 0098/100, training time: 6.4s, inference time: 0.4s
train loss: 0.8927, val_loss: 5.1668
2022-01-13 03:30:50 | epoch: 0099/100, training time: 6.6s, inference time: 0.4s
train loss: 0.9191, val_loss: 4.9783
2022-01-13 03:30:57 | epoch: 0100/100, training time: 6.8s, inference time: 0.4s
train loss: 0.8791, val_loss: 5.2113
Training and validation are completed, and model has been stored as ./output/basic/model.pkl
**** testing model ****
loading model from ./output/basic/model.pkl
model restored!
evaluating...
testing time: 0.7s
                MAE		RMSE		MAPE
train            0.55		0.83		8.39%
val              1.43		2.29		22.01%
test             1.23		2.09		18.65%
performance in each prediction step
step: 01         1.23		2.09		18.65%
average:         1.23		2.09		18.65%
total time: 11.6min
