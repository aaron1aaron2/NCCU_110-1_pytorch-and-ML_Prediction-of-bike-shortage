K=8, L=1, SE_file='./data/train_data/SE/test_adj/adj0.00124/SE.txt', batch_size=24, d=8, decay_epoch=10, device='cuda', learning_rate=0.01, log_file='./output/adj_threshold_experiment__th(0.00124)_25-percentile/log.txt', max_epoch=50, model_file='./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl', num_his=5, num_pred=1, output_folder='./output/adj_threshold_experiment__th(0.00124)_25-percentile', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/adj_threshold_experiment__th(0.00124)_25-percentile
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-11 15:58:35 | epoch: 0001/50, training time: 9.5s, inference time: 0.4s
train loss: 4.3260, val_loss: 3.8024
val loss decrease from inf to 3.8024, saving model to ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
2022-01-11 15:58:45 | epoch: 0002/50, training time: 9.4s, inference time: 0.4s
train loss: 3.1471, val_loss: 3.6163
val loss decrease from 3.8024 to 3.6163, saving model to ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
2022-01-11 15:58:55 | epoch: 0003/50, training time: 9.3s, inference time: 0.4s
train loss: 3.0619, val_loss: 3.5087
val loss decrease from 3.6163 to 3.5087, saving model to ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
2022-01-11 15:59:05 | epoch: 0004/50, training time: 9.4s, inference time: 0.4s
train loss: 3.0365, val_loss: 3.5542
2022-01-11 15:59:14 | epoch: 0005/50, training time: 9.4s, inference time: 0.4s
train loss: 2.9229, val_loss: 3.5567
2022-01-11 15:59:24 | epoch: 0006/50, training time: 9.4s, inference time: 0.4s
train loss: 2.9063, val_loss: 3.4897
val loss decrease from 3.5087 to 3.4897, saving model to ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
2022-01-11 15:59:34 | epoch: 0007/50, training time: 9.4s, inference time: 0.4s
train loss: 2.8696, val_loss: 3.4408
val loss decrease from 3.4897 to 3.4408, saving model to ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
2022-01-11 15:59:44 | epoch: 0008/50, training time: 9.3s, inference time: 0.4s
train loss: 2.8334, val_loss: 3.9001
2022-01-11 15:59:53 | epoch: 0009/50, training time: 9.4s, inference time: 0.4s
train loss: 2.8087, val_loss: 3.4082
val loss decrease from 3.4408 to 3.4082, saving model to ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
2022-01-11 16:00:03 | epoch: 0010/50, training time: 9.4s, inference time: 0.4s
train loss: 2.7733, val_loss: 3.4532
2022-01-11 16:00:13 | epoch: 0011/50, training time: 9.5s, inference time: 0.4s
train loss: 2.6790, val_loss: 3.6760
2022-01-11 16:00:23 | epoch: 0012/50, training time: 9.3s, inference time: 0.4s
train loss: 2.6692, val_loss: 3.4268
2022-01-11 16:00:33 | epoch: 0013/50, training time: 9.5s, inference time: 0.4s
train loss: 2.6362, val_loss: 3.5252
2022-01-11 16:00:43 | epoch: 0014/50, training time: 9.5s, inference time: 0.4s
train loss: 2.6083, val_loss: 3.4598
2022-01-11 16:00:52 | epoch: 0015/50, training time: 9.4s, inference time: 0.4s
train loss: 2.5534, val_loss: 3.4622
2022-01-11 16:01:02 | epoch: 0016/50, training time: 9.4s, inference time: 0.4s
train loss: 2.5256, val_loss: 3.5180
2022-01-11 16:01:12 | epoch: 0017/50, training time: 9.5s, inference time: 0.4s
train loss: 2.5047, val_loss: 3.7310
2022-01-11 16:01:22 | epoch: 0018/50, training time: 9.5s, inference time: 0.4s
train loss: 2.4980, val_loss: 3.4297
2022-01-11 16:01:32 | epoch: 0019/50, training time: 9.5s, inference time: 0.4s
train loss: 2.4244, val_loss: 3.6901
2022-01-11 16:01:42 | epoch: 0020/50, training time: 9.6s, inference time: 0.4s
train loss: 2.4146, val_loss: 3.5793
2022-01-11 16:01:52 | epoch: 0021/50, training time: 9.4s, inference time: 0.4s
train loss: 2.3135, val_loss: 3.6950
2022-01-11 16:02:02 | epoch: 0022/50, training time: 9.4s, inference time: 0.4s
train loss: 2.2069, val_loss: 3.7750
2022-01-11 16:02:11 | epoch: 0023/50, training time: 9.3s, inference time: 0.4s
train loss: 2.2085, val_loss: 3.7682
2022-01-11 16:02:21 | epoch: 0024/50, training time: 9.3s, inference time: 0.4s
train loss: 2.1884, val_loss: 3.6385
2022-01-11 16:02:31 | epoch: 0025/50, training time: 9.4s, inference time: 0.4s
train loss: 2.1696, val_loss: 3.4316
2022-01-11 16:02:40 | epoch: 0026/50, training time: 9.3s, inference time: 0.4s
train loss: 2.1676, val_loss: 3.6213
2022-01-11 16:02:50 | epoch: 0027/50, training time: 9.4s, inference time: 0.4s
train loss: 2.1020, val_loss: 3.6837
2022-01-11 16:03:00 | epoch: 0028/50, training time: 9.4s, inference time: 0.4s
train loss: 2.0468, val_loss: 3.8306
2022-01-11 16:03:10 | epoch: 0029/50, training time: 9.3s, inference time: 0.4s
train loss: 2.0594, val_loss: 3.7503
2022-01-11 16:03:20 | epoch: 0030/50, training time: 9.4s, inference time: 0.4s
train loss: 2.0172, val_loss: 3.9815
2022-01-11 16:03:30 | epoch: 0031/50, training time: 9.5s, inference time: 0.4s
train loss: 1.9463, val_loss: 3.9460
2022-01-11 16:03:39 | epoch: 0032/50, training time: 9.4s, inference time: 0.4s
train loss: 1.8899, val_loss: 3.7932
2022-01-11 16:03:49 | epoch: 0033/50, training time: 9.3s, inference time: 0.4s
train loss: 1.8551, val_loss: 3.7911
2022-01-11 16:03:59 | epoch: 0034/50, training time: 9.5s, inference time: 0.4s
train loss: 1.8106, val_loss: 3.9526
2022-01-11 16:04:09 | epoch: 0035/50, training time: 9.4s, inference time: 0.4s
train loss: 1.8040, val_loss: 4.1004
2022-01-11 16:04:19 | epoch: 0036/50, training time: 9.4s, inference time: 0.4s
train loss: 1.8188, val_loss: 4.0246
2022-01-11 16:04:29 | epoch: 0037/50, training time: 9.5s, inference time: 0.4s
train loss: 1.7851, val_loss: 3.9833
2022-01-11 16:04:38 | epoch: 0038/50, training time: 9.4s, inference time: 0.4s
train loss: 1.7805, val_loss: 3.8934
2022-01-11 16:04:48 | epoch: 0039/50, training time: 9.4s, inference time: 0.4s
train loss: 1.7519, val_loss: 3.8385
2022-01-11 16:04:58 | epoch: 0040/50, training time: 9.3s, inference time: 0.4s
train loss: 1.6962, val_loss: 3.9284
2022-01-11 16:05:08 | epoch: 0041/50, training time: 9.4s, inference time: 0.4s
train loss: 1.6434, val_loss: 3.9695
2022-01-11 16:05:17 | epoch: 0042/50, training time: 9.4s, inference time: 0.4s
train loss: 1.6267, val_loss: 4.1482
2022-01-11 16:05:27 | epoch: 0043/50, training time: 9.4s, inference time: 0.4s
train loss: 1.6346, val_loss: 4.1209
2022-01-11 16:05:37 | epoch: 0044/50, training time: 9.7s, inference time: 0.4s
train loss: 1.6214, val_loss: 3.9440
2022-01-11 16:05:47 | epoch: 0045/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5964, val_loss: 4.0771
2022-01-11 16:05:57 | epoch: 0046/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5798, val_loss: 3.9007
2022-01-11 16:06:07 | epoch: 0047/50, training time: 9.6s, inference time: 0.4s
train loss: 1.5409, val_loss: 4.1296
2022-01-11 16:06:17 | epoch: 0048/50, training time: 9.6s, inference time: 0.4s
train loss: 1.5412, val_loss: 4.2122
2022-01-11 16:06:27 | epoch: 0049/50, training time: 9.7s, inference time: 0.4s
train loss: 1.6042, val_loss: 4.0808
2022-01-11 16:06:37 | epoch: 0050/50, training time: 9.5s, inference time: 0.4s
train loss: 1.5238, val_loss: 4.0375
Training and validation are completed, and model has been stored as ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
**** testing model ****
loading model from ./output/adj_threshold_experiment__th(0.00124)_25-percentile/model.pkl
model restored!
evaluating...
testing time: 0.8s
                MAE		RMSE		MAPE
train            0.71		1.15		10.76%
val              1.23		2.04		17.53%
test             1.06		1.88		15.22%
performance in each prediction step
step: 01         1.06		1.88		15.22%
average:         1.06		1.88		15.22%
total time: 8.3min
