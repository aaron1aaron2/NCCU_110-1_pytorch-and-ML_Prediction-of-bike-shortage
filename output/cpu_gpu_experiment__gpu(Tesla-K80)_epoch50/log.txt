K=8, L=1, SE_file='data/train_data/SE/basic/SE.txt', batch_size=6, d=8, decay_epoch=10, device='cuda', learning_rate=0.001, log_file='./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/log.txt', max_epoch=50, model_file='./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl', num_his=5, num_pred=1, output_folder='./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-09 14:13:37 | epoch: 0001/50, training time: 29.8s, inference time: 1.2s
train loss: 4.6762, val_loss: 3.9603
val loss decrease from inf to 3.9603, saving model to ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
2022-01-09 14:14:08 | epoch: 0002/50, training time: 29.8s, inference time: 1.2s
train loss: 3.6548, val_loss: 3.7253
val loss decrease from 3.9603 to 3.7253, saving model to ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
2022-01-09 14:14:39 | epoch: 0003/50, training time: 29.8s, inference time: 1.2s
train loss: 3.4886, val_loss: 3.6307
val loss decrease from 3.7253 to 3.6307, saving model to ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
2022-01-09 14:15:10 | epoch: 0004/50, training time: 29.7s, inference time: 1.2s
train loss: 3.3845, val_loss: 3.6403
2022-01-09 14:15:40 | epoch: 0005/50, training time: 29.7s, inference time: 1.2s
train loss: 3.2783, val_loss: 3.4552
val loss decrease from 3.6307 to 3.4552, saving model to ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
2022-01-09 14:16:11 | epoch: 0006/50, training time: 29.7s, inference time: 1.2s
train loss: 3.2748, val_loss: 3.5355
2022-01-09 14:16:42 | epoch: 0007/50, training time: 29.7s, inference time: 1.2s
train loss: 3.1980, val_loss: 3.5163
2022-01-09 14:17:13 | epoch: 0008/50, training time: 29.7s, inference time: 1.2s
train loss: 3.1527, val_loss: 3.4793
2022-01-09 14:17:44 | epoch: 0009/50, training time: 29.8s, inference time: 1.2s
train loss: 3.1325, val_loss: 3.5022
2022-01-09 14:18:15 | epoch: 0010/50, training time: 29.7s, inference time: 1.2s
train loss: 3.0734, val_loss: 3.5004
2022-01-09 14:18:46 | epoch: 0011/50, training time: 29.8s, inference time: 1.2s
train loss: 3.0375, val_loss: 3.4983
2022-01-09 14:19:17 | epoch: 0012/50, training time: 29.8s, inference time: 1.2s
train loss: 3.0081, val_loss: 3.3993
val loss decrease from 3.4552 to 3.3993, saving model to ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
2022-01-09 14:19:48 | epoch: 0013/50, training time: 29.8s, inference time: 1.2s
train loss: 2.9441, val_loss: 3.4504
2022-01-09 14:20:19 | epoch: 0014/50, training time: 29.6s, inference time: 1.2s
train loss: 2.9531, val_loss: 3.5631
2022-01-09 14:20:50 | epoch: 0015/50, training time: 29.7s, inference time: 1.2s
train loss: 2.8649, val_loss: 3.5106
2022-01-09 14:21:21 | epoch: 0016/50, training time: 29.8s, inference time: 1.2s
train loss: 2.8787, val_loss: 3.4648
2022-01-09 14:21:52 | epoch: 0017/50, training time: 29.9s, inference time: 1.2s
train loss: 2.8312, val_loss: 3.5077
2022-01-09 14:22:23 | epoch: 0018/50, training time: 29.7s, inference time: 1.2s
train loss: 2.7792, val_loss: 3.4369
2022-01-09 14:22:54 | epoch: 0019/50, training time: 29.7s, inference time: 1.2s
train loss: 2.6922, val_loss: 3.4588
2022-01-09 14:23:24 | epoch: 0020/50, training time: 29.7s, inference time: 1.2s
train loss: 2.6756, val_loss: 3.5539
2022-01-09 14:23:55 | epoch: 0021/50, training time: 29.8s, inference time: 1.2s
train loss: 2.5729, val_loss: 3.7879
2022-01-09 14:24:26 | epoch: 0022/50, training time: 29.8s, inference time: 1.2s
train loss: 2.5836, val_loss: 3.9053
2022-01-09 14:24:57 | epoch: 0023/50, training time: 29.7s, inference time: 1.2s
train loss: 2.5196, val_loss: 3.8068
2022-01-09 14:25:28 | epoch: 0024/50, training time: 29.8s, inference time: 1.2s
train loss: 2.4929, val_loss: 3.8699
2022-01-09 14:25:59 | epoch: 0025/50, training time: 29.6s, inference time: 1.2s
train loss: 2.4324, val_loss: 3.9235
2022-01-09 14:26:30 | epoch: 0026/50, training time: 29.7s, inference time: 1.2s
train loss: 2.4185, val_loss: 3.6117
2022-01-09 14:27:01 | epoch: 0027/50, training time: 29.8s, inference time: 1.2s
train loss: 2.4020, val_loss: 3.6549
2022-01-09 14:27:32 | epoch: 0028/50, training time: 29.7s, inference time: 1.2s
train loss: 2.3049, val_loss: 4.0045
2022-01-09 14:28:03 | epoch: 0029/50, training time: 29.6s, inference time: 1.2s
train loss: 2.2855, val_loss: 3.9677
2022-01-09 14:28:34 | epoch: 0030/50, training time: 29.8s, inference time: 1.2s
train loss: 2.2650, val_loss: 3.8202
2022-01-09 14:29:05 | epoch: 0031/50, training time: 29.9s, inference time: 1.2s
train loss: 2.2221, val_loss: 4.1592
2022-01-09 14:29:36 | epoch: 0032/50, training time: 30.0s, inference time: 1.2s
train loss: 2.1819, val_loss: 3.8567
2022-01-09 14:30:07 | epoch: 0033/50, training time: 30.0s, inference time: 1.2s
train loss: 2.1543, val_loss: 3.9789
2022-01-09 14:30:38 | epoch: 0034/50, training time: 29.9s, inference time: 1.2s
train loss: 2.1409, val_loss: 3.8293
2022-01-09 14:31:09 | epoch: 0035/50, training time: 29.6s, inference time: 1.2s
train loss: 2.1382, val_loss: 3.8443
2022-01-09 14:31:40 | epoch: 0036/50, training time: 29.5s, inference time: 1.2s
train loss: 2.0766, val_loss: 3.9773
2022-01-09 14:32:10 | epoch: 0037/50, training time: 29.4s, inference time: 1.2s
train loss: 2.1134, val_loss: 4.1683
2022-01-09 14:32:41 | epoch: 0038/50, training time: 29.7s, inference time: 1.2s
train loss: 2.0357, val_loss: 4.2543
2022-01-09 14:33:12 | epoch: 0039/50, training time: 29.9s, inference time: 1.2s
train loss: 2.0420, val_loss: 4.1277
2022-01-09 14:33:43 | epoch: 0040/50, training time: 29.9s, inference time: 1.2s
train loss: 2.0077, val_loss: 4.2579
2022-01-09 14:34:14 | epoch: 0041/50, training time: 30.0s, inference time: 1.2s
train loss: 1.9347, val_loss: 4.0653
2022-01-09 14:34:45 | epoch: 0042/50, training time: 29.9s, inference time: 1.2s
train loss: 1.9648, val_loss: 4.2905
2022-01-09 14:35:16 | epoch: 0043/50, training time: 29.7s, inference time: 1.2s
train loss: 1.9134, val_loss: 4.2024
2022-01-09 14:35:47 | epoch: 0044/50, training time: 29.8s, inference time: 1.2s
train loss: 1.9027, val_loss: 4.1494
2022-01-09 14:36:18 | epoch: 0045/50, training time: 29.8s, inference time: 1.2s
train loss: 1.9007, val_loss: 4.3538
2022-01-09 14:36:49 | epoch: 0046/50, training time: 29.7s, inference time: 1.2s
train loss: 1.8844, val_loss: 4.0880
2022-01-09 14:37:20 | epoch: 0047/50, training time: 30.1s, inference time: 1.2s
train loss: 1.8555, val_loss: 4.1902
2022-01-09 14:37:52 | epoch: 0048/50, training time: 30.0s, inference time: 1.2s
train loss: 1.8538, val_loss: 4.4818
2022-01-09 14:38:23 | epoch: 0049/50, training time: 30.1s, inference time: 1.2s
train loss: 1.8697, val_loss: 4.3774
2022-01-09 14:38:54 | epoch: 0050/50, training time: 30.1s, inference time: 1.2s
train loss: 1.8555, val_loss: 4.2820
Training and validation are completed, and model has been stored as ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
**** testing model ****
loading model from ./output/cpu_gpu_experiment__gpu(Tesla-K80)_epoch50/model.pkl
model restored!
evaluating...
testing time: 2.4s
                MAE		RMSE		MAPE
train            0.70		1.12		11.37%
val              1.30		2.09		21.15%
test             1.11		1.92		18.13%
performance in each prediction step
step: 01         1.11		1.92		18.13%
average:         1.11		1.92		18.13%
total time: 26.0min
