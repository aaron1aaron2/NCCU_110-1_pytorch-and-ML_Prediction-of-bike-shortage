K=8, L=1, SE_file='data/train_data/SE/basic/SE.txt', batch_size=20, d=8, decay_epoch=10, device='cuda', learning_rate=0.001, log_file='./output/hyperparameters_experiment__gpu_bs20/log.txt', max_epoch=50, model_file='./output/hyperparameters_experiment__gpu_bs20/model.pkl', num_his=5, num_pred=1, output_folder='./output/hyperparameters_experiment__gpu_bs20', patience=100, test_ratio=0.2, time_slot=10, traffic_file='data/train_data/data.h5', train_ratio=0.7, val_ratio=0.1, view_batch_freq=100
main output folder./output/hyperparameters_experiment__gpu_bs20
loading data...
trainX: torch.Size([3622, 5, 26])		 trainY: torch.Size([3622, 1, 26])
valX:   torch.Size([513, 5, 26])		valY:   torch.Size([513, 1, 26])
testX:   torch.Size([1031, 5, 26])		testY:   torch.Size([1031, 1, 26])
mean:   11.0472		std:   6.8502
data loaded!
compiling model...
trainable parameters: 209,923
**** training model ****
2022-01-10 02:38:34 | epoch: 0001/50, training time: 12.1s, inference time: 0.5s
train loss: 5.4505, val_loss: 4.0086
val loss decrease from inf to 4.0086, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:38:47 | epoch: 0002/50, training time: 12.2s, inference time: 0.5s
train loss: 3.4312, val_loss: 3.8628
val loss decrease from 4.0086 to 3.8628, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:38:59 | epoch: 0003/50, training time: 11.9s, inference time: 0.5s
train loss: 3.3010, val_loss: 3.7532
val loss decrease from 3.8628 to 3.7532, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:39:12 | epoch: 0004/50, training time: 11.9s, inference time: 0.5s
train loss: 3.2104, val_loss: 3.6685
val loss decrease from 3.7532 to 3.6685, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:39:24 | epoch: 0005/50, training time: 12.1s, inference time: 0.5s
train loss: 3.1396, val_loss: 3.6845
2022-01-10 02:39:37 | epoch: 0006/50, training time: 12.0s, inference time: 0.5s
train loss: 3.0849, val_loss: 3.5583
val loss decrease from 3.6685 to 3.5583, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:39:49 | epoch: 0007/50, training time: 12.0s, inference time: 0.5s
train loss: 2.9768, val_loss: 3.5376
val loss decrease from 3.5583 to 3.5376, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:40:02 | epoch: 0008/50, training time: 12.0s, inference time: 0.5s
train loss: 2.9238, val_loss: 3.5263
val loss decrease from 3.5376 to 3.5263, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:40:14 | epoch: 0009/50, training time: 12.0s, inference time: 0.5s
train loss: 2.8795, val_loss: 3.5830
2022-01-10 02:40:27 | epoch: 0010/50, training time: 12.1s, inference time: 0.5s
train loss: 2.8201, val_loss: 3.4894
val loss decrease from 3.5263 to 3.4894, saving model to ./output/hyperparameters_experiment__gpu_bs20/model.pkl
2022-01-10 02:40:39 | epoch: 0011/50, training time: 12.0s, inference time: 0.5s
train loss: 2.7758, val_loss: 3.5069
2022-01-10 02:40:52 | epoch: 0012/50, training time: 12.2s, inference time: 0.5s
train loss: 2.7396, val_loss: 3.5421
2022-01-10 02:41:05 | epoch: 0013/50, training time: 12.1s, inference time: 0.5s
train loss: 2.6718, val_loss: 3.5631
2022-01-10 02:41:17 | epoch: 0014/50, training time: 12.1s, inference time: 0.5s
train loss: 2.6439, val_loss: 3.6097
2022-01-10 02:41:30 | epoch: 0015/50, training time: 12.0s, inference time: 0.5s
train loss: 2.5848, val_loss: 3.5826
2022-01-10 02:41:42 | epoch: 0016/50, training time: 12.1s, inference time: 0.5s
train loss: 2.5703, val_loss: 3.5223
2022-01-10 02:41:55 | epoch: 0017/50, training time: 12.1s, inference time: 0.5s
train loss: 2.5407, val_loss: 3.5258
2022-01-10 02:42:07 | epoch: 0018/50, training time: 12.0s, inference time: 0.5s
train loss: 2.5124, val_loss: 3.5860
2022-01-10 02:42:20 | epoch: 0019/50, training time: 12.0s, inference time: 0.5s
train loss: 2.4162, val_loss: 3.5772
2022-01-10 02:42:32 | epoch: 0020/50, training time: 11.9s, inference time: 0.5s
train loss: 2.3494, val_loss: 3.4983
2022-01-10 02:42:45 | epoch: 0021/50, training time: 12.1s, inference time: 0.5s
train loss: 2.2996, val_loss: 3.6223
2022-01-10 02:42:57 | epoch: 0022/50, training time: 12.0s, inference time: 0.5s
train loss: 2.2774, val_loss: 3.6307
2022-01-10 02:43:10 | epoch: 0023/50, training time: 11.9s, inference time: 0.5s
train loss: 2.2174, val_loss: 3.8367
2022-01-10 02:43:22 | epoch: 0024/50, training time: 11.9s, inference time: 0.5s
train loss: 2.1773, val_loss: 3.6599
2022-01-10 02:43:35 | epoch: 0025/50, training time: 11.9s, inference time: 0.5s
train loss: 2.1397, val_loss: 4.1273
2022-01-10 02:43:47 | epoch: 0026/50, training time: 12.0s, inference time: 0.5s
train loss: 2.1092, val_loss: 3.7815
2022-01-10 02:44:00 | epoch: 0027/50, training time: 12.0s, inference time: 0.5s
train loss: 2.0480, val_loss: 3.6224
2022-01-10 02:44:12 | epoch: 0028/50, training time: 12.0s, inference time: 0.5s
train loss: 2.0128, val_loss: 3.7076
2022-01-10 02:44:25 | epoch: 0029/50, training time: 12.0s, inference time: 0.5s
train loss: 1.9876, val_loss: 3.9163
2022-01-10 02:44:37 | epoch: 0030/50, training time: 12.2s, inference time: 0.5s
train loss: 1.9639, val_loss: 3.8052
2022-01-10 02:44:50 | epoch: 0031/50, training time: 12.2s, inference time: 0.5s
train loss: 1.8822, val_loss: 3.8624
2022-01-10 02:45:04 | epoch: 0032/50, training time: 13.0s, inference time: 0.5s
train loss: 1.8919, val_loss: 3.9821
2022-01-10 02:45:17 | epoch: 0033/50, training time: 12.7s, inference time: 0.5s
train loss: 1.8105, val_loss: 4.0117
2022-01-10 02:45:30 | epoch: 0034/50, training time: 12.9s, inference time: 0.5s
train loss: 1.8446, val_loss: 3.9256
2022-01-10 02:45:44 | epoch: 0035/50, training time: 13.0s, inference time: 0.5s
train loss: 1.7299, val_loss: 3.9552
2022-01-10 02:45:57 | epoch: 0036/50, training time: 12.7s, inference time: 0.5s
train loss: 1.7728, val_loss: 3.9477
2022-01-10 02:46:10 | epoch: 0037/50, training time: 12.3s, inference time: 0.5s
train loss: 1.7144, val_loss: 3.9919
2022-01-10 02:46:23 | epoch: 0038/50, training time: 12.4s, inference time: 0.5s
train loss: 1.6685, val_loss: 4.0437
2022-01-10 02:46:36 | epoch: 0039/50, training time: 12.3s, inference time: 0.5s
train loss: 1.7607, val_loss: 4.1162
2022-01-10 02:46:49 | epoch: 0040/50, training time: 13.0s, inference time: 0.6s
train loss: 1.6913, val_loss: 4.2632
2022-01-10 02:47:03 | epoch: 0041/50, training time: 13.1s, inference time: 0.5s
train loss: 1.6232, val_loss: 4.1278
2022-01-10 02:47:16 | epoch: 0042/50, training time: 12.7s, inference time: 0.5s
train loss: 1.5835, val_loss: 4.1709
2022-01-10 02:47:29 | epoch: 0043/50, training time: 12.4s, inference time: 0.5s
train loss: 1.5730, val_loss: 4.4107
2022-01-10 02:47:43 | epoch: 0044/50, training time: 12.9s, inference time: 0.5s
train loss: 1.5123, val_loss: 4.1187
2022-01-10 02:47:56 | epoch: 0045/50, training time: 12.6s, inference time: 0.5s
train loss: 1.5559, val_loss: 4.3387
2022-01-10 02:48:09 | epoch: 0046/50, training time: 12.5s, inference time: 0.5s
train loss: 1.5195, val_loss: 4.2590
2022-01-10 02:48:22 | epoch: 0047/50, training time: 12.4s, inference time: 0.5s
train loss: 1.4613, val_loss: 4.2141
2022-01-10 02:48:34 | epoch: 0048/50, training time: 12.3s, inference time: 0.5s
train loss: 1.4734, val_loss: 4.3613
2022-01-10 02:48:47 | epoch: 0049/50, training time: 12.4s, inference time: 0.5s
train loss: 1.4897, val_loss: 4.5477
2022-01-10 02:49:00 | epoch: 0050/50, training time: 12.3s, inference time: 0.5s
train loss: 1.4206, val_loss: 4.3026
Training and validation are completed, and model has been stored as ./output/hyperparameters_experiment__gpu_bs20/model.pkl
**** testing model ****
loading model from ./output/hyperparameters_experiment__gpu_bs20/model.pkl
model restored!
evaluating...
testing time: 1.0s
                MAE		RMSE		MAPE
train            0.69		1.08		11.12%
val              1.29		2.09		19.33%
test             1.12		1.94		17.48%
performance in each prediction step
step: 01         1.12		1.94		17.48%
average:         1.12		1.94		17.48%
total time: 10.7min
